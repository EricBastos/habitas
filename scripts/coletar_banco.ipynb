{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce59d7-7b04-460b-b02a-537b21c19f89",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from multiprocessing.dummy import Pool  # Using a thread pool for parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf228b-7618-4c85-a1f5-f726f0b75bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to extract information from a single URL\n",
    "def extract_info(url):\n",
    "    print(url, \"started\")\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        # Sleep for 5 seconds and then retry\n",
    "        print(f\"Received a non-200 status code ({response.status_code}) for URL: {url}. Skipped\")\n",
    "        data = []\n",
    "        data.append(['-', '-', '-', '-', '-', '-', '-', '-', '-'])\n",
    "        return data\n",
    "    \n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    tree_panels = soup.find_all('div', class_='panel panel-default')\n",
    "    \n",
    "    data = []\n",
    "    for panel in tree_panels:\n",
    "        p_elements = panel.find_all('p')\n",
    "        \n",
    "        # Filter the <p> elements to find the one with \"Nome Popular\"\n",
    "        nome_popular_element = next((p for p in p_elements if 'Nome Popular:' in p.get_text()), None)\n",
    "        nome_popular = nome_popular_element.find('strong').text if nome_popular_element else None\n",
    "\n",
    "        # Filter the <p> elements to find the one with \"Nome Científico\"\n",
    "        nome_cientifico_element = next((p for p in p_elements if 'Nome Científico:' in p.get_text()), None)\n",
    "        nome_cientifico = nome_cientifico_element.find('i').text if nome_cientifico_element else None\n",
    "\n",
    "        # Filter the <p> elements to find the one with \"DAP\"\n",
    "        dap_element = next((p for p in p_elements if 'DAP (Diâmetro à altura do peito):' in p.get_text()), None)\n",
    "        dap = dap_element.find('strong').text if dap_element else None\n",
    "\n",
    "        # Filter the <p> elements to find the one with \"Altura\"\n",
    "        altura_element = next((p for p in p_elements if 'Altura:' in p.get_text()), None)\n",
    "        altura = altura_element.find('strong').text if altura_element else None\n",
    "\n",
    "        # Filter the <p> elements to find the one with \"Data da Coleta\"\n",
    "        data_coleta_element = next((p for p in p_elements if 'Data da Coleta:' in p.get_text()), None)\n",
    "        data_coleta = data_coleta_element.find('strong').text if data_coleta_element else None\n",
    "\n",
    "        # Find the element with latitude and longitude information\n",
    "        lat_long_element = next((p for p in p_elements if 'Latitude:' in p.get_text()), None)\n",
    "\n",
    "        if lat_long_element:\n",
    "            strong_elements = lat_long_element.find_all('strong')\n",
    "            if len(strong_elements) == 2:\n",
    "                latitude = strong_elements[0].text.strip()\n",
    "                longitude = strong_elements[1].text.strip()\n",
    "            else:\n",
    "                latitude = None\n",
    "                longitude = None\n",
    "        else:\n",
    "            latitude = None\n",
    "            longitude = None\n",
    "\n",
    "\n",
    "        # Extract links to laudos\n",
    "        laudo_links = [a['href'] for a in panel.find_all('a', href=True) if \"Laudo Nº\" in a.get_text()]\n",
    "\n",
    "        # Extract image sources\n",
    "        image_sources = [img['src'] for img in panel.find_all('img', alt=True)]\n",
    "        \n",
    "        data.append([nome_popular, nome_cientifico, dap, altura, data_coleta, latitude, longitude, \", \".join(laudo_links), \", \".join(image_sources)])\n",
    "        \n",
    "        print(url, \"success\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3905f-a06f-48f2-b4c1-22b5b6050ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of URLs to fetch (1 to 20)\n",
    "base_url = 'https://arvores.sjc.sp.gov.br/'\n",
    "urls = [f'{base_url}{i}' for i in range(5000, 10000)]\n",
    "\n",
    "# Set up a thread pool for parallel processing with 10 workers\n",
    "pool = Pool(32)\n",
    "\n",
    "# Use the pool to process the URLs and extract information\n",
    "results = pool.map(extract_info, urls)\n",
    "    \n",
    "# Close the pool\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023a27fe-5afa-44d4-aea3-0eb462ef1645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame\n",
    "columns = ['Nome Popular', 'Nome Cientifico', 'DAP', 'Altura', 'Data Coleta', 'Latitude', 'Longitude', 'Laudos', 'Image Sources']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Append the results to the DataFrame with an ID column\n",
    "for i, result in enumerate(results, 1):\n",
    "    df = pd.concat([df, pd.DataFrame(result, columns=columns)])\n",
    "    \n",
    "df['ID'] = range(5000, len(df)+5000)\n",
    "df.set_index('ID', inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165679e7-c3d8-4601-a467-ab6b127f8cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('trees2.csv',sep=';',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a914b36-8a25-4e46-bcb1-19ecfa5d6ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
